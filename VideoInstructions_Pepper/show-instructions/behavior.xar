<?xml version="1.0" encoding="UTF-8" ?><ChoregrapheProject xmlns="http://www.aldebaran-robotics.com/schema/choregraphe/project.xsd" xar_version="3"><Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0"><bitmap>media/images/box/root.png</bitmap><script language="4"><content><![CDATA[]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /><Timeline enable="0"><BehaviorLayer name="behavior_layer1"><BehaviorKeyframe name="keyframe1" index="1"><Diagram><Box name="Show Instructions" id="1" localization="8" tooltip="This box contains a Python script that allows the robot to show the instructions for the activity passed as parameter." x="189" y="55"><bitmap>media/images/box/box-python-script.png</bitmap><script language="4"><content><![CDATA[import sys
import qi
import os
import urllib2
import re
from naoqi import ALProxy


class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.tablet_service = ALProxy("ALTabletService")
        self.memory = ALProxy("ALMemory")
        self.animated_speech = ALProxy("ALAnimatedSpeech")
        self.voice_speed = "\\RSPD=" + str(self.memory.getData("CAIR/voice_speed")) + "\\"
        self.language = self.memory.getData("CAIR/language")
        self.configuration = {"bodyLanguageMode": "contextual"}
        self.memory.subscribeToEvent("TouchChanged", self.getName(), "onTouched")
        self.al = ALProxy("ALAutonomousLife")
        self.isRunning = True
        self.isAlive = True

    def setAutonomousAbilities(self, blinking, background, awareness, listening, speaking):
        self.al.setAutonomousAbilityEnabled("AutonomousBlinking", blinking)
        self.al.setAutonomousAbilityEnabled("BackgroundMovement", background)
        self.al.setAutonomousAbilityEnabled("BasicAwareness", awareness)
        self.al.setAutonomousAbilityEnabled("ListeningMovement", listening)
        self.al.setAutonomousAbilityEnabled("SpeakingMovement", speaking)

    def onTouched(self, strVarName, value):
        self.logger.info("touched")
        self.isRunning = False

    def onLoad(self):
        pass

    def onUnload(self):
        pass

    def onInput_onStart(self):
        if self.language == "it":
            wait_msg = "Dammi un momento. Sto cercando le istruzioni."
            stop_msg = "Premi play quando vuoi guardare le istruzioni. Tocca uno dei miei sensori per uscire."
        else:
            wait_msg = "Give me a moment. I'm looking for the instructions on YouTube."
            stop_msg = "Press play when you're ready to watch the instructions. Touch one of my sensors when you want to stop."

        text = self.memory.getData("CAIR/instructions")
        self.logger.info(str(text))

        self.animated_speech.say(self.voice_speed + wait_msg, self.configuration)

        search_keyword = text.replace(" ", "+") + "+tutorial"
        html = urllib2.urlopen("https://www.youtube.com/results?search_query=" + search_keyword)
        video_ids = re.findall(r"watch\?v=(\S{11})", html.read().decode('utf-8'))
        try:
            my_url = "https://www.youtube.com/watch?v=" + video_ids[0]
            self.logger.info(str(my_url))

            # Start the application on tablet
            self.tablet_service.cleanWebview()
            self.tablet_service.loadUrl(str(my_url))
            self.tablet_service.showWebview()
            self.animated_speech.say(self.voice_speed + stop_msg, self.configuration)

            while self.isRunning:
                pass

            self.tablet_service.cleanWebview()
            self.tablet_service.hideWebview()
        except IndexError as e:
            if self.language == "it":
                error_msg = "Mi dispiace non ho trovato il video su YouTube"
            else:
                error_msg = "I'm sorry I didn't find the video on YouTube"
            self.animated_speech.say(self.voice_speed + error_msg, self.configuration)
            print(e)

        self.memory.removeData("CAIR/instructions")
        self.onInput_onStop()

    def onInput_onStop(self):
        self.onUnload() #it is recommended to reuse the clean-up as the box is stopped
        self.onStopped() #activate the output of the box]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /></Box><Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="2" /><Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="4" /></Diagram></BehaviorKeyframe></BehaviorLayer></Timeline></Box></ChoregrapheProject>