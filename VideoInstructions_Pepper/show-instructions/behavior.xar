<?xml version="1.0" encoding="UTF-8" ?><ChoregrapheProject xmlns="http://www.aldebaran-robotics.com/schema/choregraphe/project.xsd" xar_version="3"><Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0"><bitmap>media/images/box/root.png</bitmap><script language="4"><content><![CDATA[]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /><Timeline enable="0"><BehaviorLayer name="behavior_layer1"><BehaviorKeyframe name="keyframe1" index="1"><Diagram><Box name="Show Instructions" id="1" localization="8" tooltip="This box contains a Python script that allows the robot to show the instructions for the activity passed as parameter." x="189" y="55"><bitmap>media/images/box/box-python-script.png</bitmap><script language="4"><content><![CDATA[import sys
import qi
import os
import urllib2
import re
from naoqi import ALProxy


class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.tablet_service = ALProxy("ALTabletService")
        self.memory = ALProxy("ALMemory")
        self.animated_speech = ALProxy("ALAnimatedSpeech")
        self.voice_speed = "\\RSPD=" + str(self.memory.getData("CAIR/voice_speed")) + "\\"
        self.language = self.memory.getData("CAIR/language")
        self.configuration = {"bodyLanguageMode": "contextual"}
        self.memory.subscribeToEvent("TouchChanged", self.getName(), "onTouched")
        self.sASR = ALProxy("ASR2")
        self.speech_reco_event = "Audio/RecognizedWords"
        self.al = ALProxy("ALAutonomousLife")
        self.isRunning = True
        self.isAlive = True

    def setAutonomousAbilities(self, blinking, background, awareness, listening, speaking):
        self.al.setAutonomousAbilityEnabled("AutonomousBlinking", blinking)
        self.al.setAutonomousAbilityEnabled("BackgroundMovement", background)
        self.al.setAutonomousAbilityEnabled("BasicAwareness", awareness)
        self.al.setAutonomousAbilityEnabled("ListeningMovement", listening)
        self.al.setAutonomousAbilityEnabled("SpeakingMovement", speaking)

    def onTouched(self, strVarName, value):
        self.logger.info("touched")
        self.isRunning = False

    def onLoad(self):
        pass

    def onUnload(self):
        pass

    def onInput_onStart(self):
        if self.language == "it":
            ask_activity = "Per quale attivitÃ  vuoi che ti mostri le istruzioni?"
            wait_msg = "Dammi un momento. Sto cercando le istruzioni su YouTube."
            stop_msg = "Premi play quando vuoi guardare le istruzioni. Tocca uno dei miei sensori per uscire."
        else:
            ask_activity = "For which activity do you want me to show you the instructions?"
            wait_msg = "Give me a moment. I'm looking for the instructions on YouTube."
            stop_msg = "Press play when you're ready to watch the instructions. Touch one of my sensors when you want to stop."
        # Check if the parameter is in memory
        try:
            text = self.memory.getData("CAIR/instructions")
            self.logger.info(str(text))
            if text == "None" or text == "":
                raise Exception("No data")
        # If there is no parameter, ask for it
        except:
            self.animated_speech.say(self.voice_speed + ask_activity, self.configuration)

            # Start speech recognition
            self.sASR.startReco("English", False, True)
            self.setAutonomousAbilities(True, True, True, True, True)

            start_time_silence = time.time() + 1800

            sentence = ""
            reco_speech = self.memory.getData(self.speech_reco_event)
            self.logger.info(str(reco_speech))
            stop = False

            while True:
                time.sleep(0.1)
                while not reco_speech:
                    time.sleep(0.1)
                    if sentence and time.time() - start_time_silence > 0.1:
                        self.sASR.stopReco()
                        self.setAutonomousAbilities(False, True, True, True, True)
                        stop = True
                        break
                    reco_speech = self.memory.getData(self.speech_reco_event)
                    print reco_speech
                sys.stdout.flush()
                if stop:
                    break
                if sentence == "":
                    sep = ""
                else:
                    sep = " "

                if reco_speech:
                    sentence = sentence + sep + reco_speech[0][0]
                start_time_silence = time.time()
                self.memory.insertData(self.speech_reco_event, [])
                reco_speech = self.memory.getData(self.speech_reco_event)

                exit_keywords = ["stop", "exit", "quit"]
                if sentence.lower() in exit_keywords:
                    self.onInput_onStop()
                    sys.exit(0)

            sentence = sentence.replace(" ", "_")
            print sentence
            self.logger.info(str(sentence))
            self.memory.insertData(self.speech_reco_event, [])
            self.memory.insertData("CAIR/instructions", str(sentence))

        text = self.memory.getData("CAIR/instructions")
        self.logger.info(str(text))

        self.animated_speech.say(self.voice_speed + wait_msg, self.configuration)

        search_keyword = text.replace(" ", "+") + "+tutorial"
        html = urllib2.urlopen("https://www.youtube.com/results?search_query=" + search_keyword)
        video_ids = re.findall(r"watch\?v=(\S{11})", html.read().decode('utf-8'))
        try:
            my_url = "https://www.youtube.com/watch?v=" + video_ids[0]
            self.logger.info(str(my_url))

            # Start the application on tablet
            self.tablet_service.cleanWebview()
            self.tablet_service.loadUrl(str(my_url))
            self.tablet_service.showWebview()
            self.animated_speech.say(self.voice_speed + stop_msg, self.configuration)

            while self.isRunning:
                pass

            self.tablet_service.cleanWebview()
            self.tablet_service.hideWebview()
        except IndexError as e:
            if self.language == "it":
                error_msg = "Mi dispiace non ho trovato il video su YouTube"
            else:
                error_msg = "I'm sorry I didn't find the video on YouTube"
            self.animated_speech.say(self.voice_speed + error_msg, self.configuration)
            print(e)

        self.memory.removeData("CAIR/instructions")
        self.onInput_onStop()

    def onInput_onStop(self):
        self.onUnload() #it is recommended to reuse the clean-up as the box is stopped
        self.onStopped() #activate the output of the box]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /></Box><Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="2" /><Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="4" /></Diagram></BehaviorKeyframe></BehaviorLayer></Timeline></Box></ChoregrapheProject>