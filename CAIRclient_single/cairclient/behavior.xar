<?xml version="1.0" encoding="UTF-8" ?><ChoregrapheProject xmlns="http://www.aldebaran-robotics.com/schema/choregraphe/project.xsd" xar_version="3"><Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0"><bitmap>media/images/box/root.png</bitmap><script language="4"><content><![CDATA[]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /><Timeline enable="0"><BehaviorLayer name="behavior_layer1"><BehaviorKeyframe name="keyframe1" index="1"><Diagram><Box name="CAIRclient single" id="1" localization="8" tooltip="This box contains a basic python script and can be used to create any python script box you would like.&#x0A;&#x0A;To edit its script, double-click on it." x="238" y="95"><bitmap>media/images/box/box-python-script.png</bitmap><script language="4"><content><![CDATA[#!usr/bin/python -tt
# -*- coding: utf-8 -*-
import qi
import sys
reload(sys)
sys.setdefaultencoding("utf-8")
app_name = "cairclient_single"
sys.path.append("/data/home/nao/.local/share/PackageManager/apps/" + app_name + "/libs/")
sys.path.append("/data/home/nao/.local/share/PackageManager/apps/" + app_name + "/")
from naoqi import ALProxy
import threading
import requests
import time
import json
import os
import pickle
import socket
import zlib
from cairlib_single.CAIRclient_SoftBank_actions import ActionManager
from cairlib_single.CAIRclient_SoftBank_utils import Utils

cineca_ip = "131.175.205.146"
local = "130.251.13.104"

server_ip = cineca_ip
audio_recorder_ip = local
port = "5000"
music_port = "5003"
request_uri = "http://" + cineca_ip + ":" + port + "/CAIR_hub"

language = "it"


class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.memory = ALProxy("ALMemory")
        self.tts = ALProxy("ALTextToSpeech")
        self.animated_speech = ALProxy("ALAnimatedSpeech")
        self.configuration = {"bodyLanguageMode": "contextual"}
        self.al = ALProxy("ALAutonomousLife")
        self.motion = ALProxy("ALMotion")
        self.behavior_manager = ALProxy("ALBehaviorManager")
        self.audio_device = ALProxy("ALAudioDevice")

        # Write the language in the memory as it is used by the actions
        if language == "it":
            self.language = self.memory.insertData("CAIR/language", "it")
            self.tts.setLanguage("Italian")
        else:
            self.language = self.memory.insertData("CAIR/language", "en")
            self.tts.setLanguage("English")

        self.memory.insertData("CAIR/server_ip", str(server_ip))
        self.memory.insertData("CAIR/music_port", str(music_port))

        self.logger.info("Setting voice speed")

        self.memory.insertData("CAIR/voice_speed", 85)
        self.voice_speed = "\\RSPD=" + str(self.memory.getData("CAIR/voice_speed")) + "\\"

        # Initialize socket and try to connec
        self.client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        self.logger.info("Trying to connect to the audio recorder socket.")
        try:
            self.client_socket.connect((audio_recorder_ip, 9090))
        except:
            if language == "it":
                to_say = "Mi dispiace, non riesco a connettermi al microfono esterno. Controlla l'indirizzo I P e riprova."
            else:
                to_say = "I'm sorry, I can't connect to external microphone. Check the IP address and try again."
            self.animated_speech.say(self.voice_speed + to_say, self.configuration)
            self.onInput_onStop()

        # Instances of the classes of the other files in the libs folder containing functions needed here
        self.plans = ActionManager(self.logger.info, self.client_socket)
        self.utils = Utils(self.logger.info, app_name, language, server_ip, port)
        self.utils.setAutonomousAbilities(True, True, True, True, True)
        self.isAlive = True

        self.dialogue_state_file_path = "/data/home/nao/.local/share/PackageManager/apps/" + app_name + "/" \
                                        "dialogue_state.json"

        # To store the previous sentence said by the robot
        self.previous_sentence = ""
        # This variable tells if the user want the robot to repeat a sentence
        self.repeat = False
        self.stop_recording = False
        self.exit_sentences = ["stop talking", "quit the application", "esci dall'app", "esci dallapp", "esci dallapplicazione"]
        self.repeat_keywords = ["repeat", "say it again", "puoi ripetere", "ripeti", "non ho capito"]
        self.stop_recording_keywords = ["smetti di ascoltare", "spegni il microfono"]
        self.passphrases = ["passo e chiudo", "cosa ne pensi"]

        # Store the number of people in front of the robot, coming from the sensor readings
        self.people = 0

        self.logger.info("Trying to connect to ALTabletService...")
        self.tablet = True
        try:
            self.tablet_service = ALProxy("ALTabletService")
        except:
            self.tablet = False

        self.audio_device = ALProxy("ALAudioDevice")
        self.audio_device.setOutputVolume(50)

        # To recognize intention of switching the mic on
        self.speech_reco_event = "Audio/RecognizedWords"
        self.asr_service = ALProxy("ALSpeechRecognition")
        # asr needs to be paused before changing the language and setting the vocabulary
        self.asr_service.pause(False)
        self.asr_service.pause(True)
        # change the language to overcome vocabulary problem
        self.asr_service.setLanguage("Italian")
        self.asr_service.setLanguage("English")
        self.vocabulary = ["ascolta", "ascoltami", "si", "no", "ciao", "ok"]
        self.asr_service.pause(True)
        self.asr_service.setVocabulary(self.vocabulary, False)
        self.asr_service.setAudioExpression(False)
        self.asr_service.setParameter("Sensitivity", 0.3)

    def onInput_onStart(self):
        try:
            if self.al.getState() != "disabled":
                # self.animated_speech.say(self.voice_speed + "Give me a moment. I need to disable Autonomous Life before we start.", self.configuration)
                self.al.setState("disabled")
        except:
            pass

        # Wake the robot up if not already up
        self.motion.wakeUp()

        # With Pepper robot, preload the images to be set on the tablet during the conversation
        if self.tablet:
            self.tablet_service.preLoadImage("http://" + self.tablet_service.robotIp() +
                                             "/apps/" + app_name + "/img/DialogueMode.png")
            self.tablet_service.preLoadImage("http://" + self.tablet_service.robotIp() +
                                             "/apps/" + app_name + "/img/ExecutionMode.png")
            self.tablet_service.preLoadImage("http://" + self.tablet_service.robotIp() +
                                             "/apps/" + app_name + "/img/PrivacyMode.png")
            self.tablet_service.showImage("http://" + self.tablet_service.robotIp() +
                                          "/apps/" + app_name + "/img/DialogueMode.png")

        # If it's the first time using the system, call the function that acquires the first state
        if not os.path.isfile(self.dialogue_state_file_path):
            self.logger.info("First user!")
            # This function creates the speakers_info and the speakers_sequence_stats files and initializes them
            # with the info of a generic user
            welcome_sentence_str = self.utils.acquire_initial_state()
            if language == "it":
                welcome_msg = "Benvenuto! "
            else:
                welcome_msg = "Welcome! "

            self.logger.info(welcome_msg + str(welcome_sentence_str))
            self.animated_speech.say(self.voice_speed + welcome_msg + str(welcome_sentence_str), self.configuration)
            self.previous_sentence = welcome_msg + welcome_sentence_str
        else:
            self.logger.info("Users are already present in the info file")
            if language == "it":
                welcome_back_msg = "È bello rivederti! Di cosa vorresti parlare?"
            else:
                welcome_back_msg = "I missed you! What would you like to talk about?"
            self.animated_speech.say(self.voice_speed + welcome_back_msg,
                                     self.configuration)
            self.previous_sentence = welcome_back_msg

        # Retrieve the states of the users and save them in a dictionary
        with open(self.dialogue_state_file_path) as f:
            dialogue_state = json.load(f)

        # Loop until the user wants to stop the conversation
        while self.isAlive:
            self.logger.info("** Listening **")
            # Tell the audio recorder that the client is ready to listen
            # Send the sentence type so that it knows if it has to wait for a passphrase
            sentence_type = dialogue_state["sentence_type"]
            self.client_socket.send(sentence_type.encode("utf-8"))
            sentence = self.client_socket.recv(1024).decode('utf-8')

            if sentence == "":
                if language == "it":
                    to_say = "Mi dispiace, c'è stato qualche problema con la connessione al microfono esterno."
                else:
                    to_say = "I'm sorry, something went wrong with the connection to the external microphone."
                self.animated_speech.say(self.voice_speed + to_say, self.configuration)
                self.onInput_onStop()

            # Add spaces at the beginning and end of user sentence to match certain keywords
            sentence = " " + sentence + " "

            # Check if the user wants to exit or wants the robot to repeat the previous sentence
            sentence = sentence.replace(".", "")
            sentence = sentence.replace("?", "")

            # Delete passphrases from the user sentence
            for passphrase in self.passphrases:
                if passphrase in sentence.lower():
                    sentence = sentence.lower().replace(passphrase, "")
            self.logger.info("sentence without passphrase: " + str(sentence))

            # Reset repeat to false, otherwise it will always repeat the previous sentence
            self.repeat = False
            self.stop_recording = False

            # If the user said one of the "Exit Application keywords"
            if any(exit_sent in sentence.lower() for exit_sent in self.exit_sentences):
                self.isAlive = False
                if language == "it":
                    goodbye_msg = "Ok, grazie per aver parlato con me! A presto!"
                else:
                    goodbye_msg = "Ok, thank you for talking with me! Goodbye."
                self.animated_speech.say(self.voice_speed + goodbye_msg, self.configuration)
                self.memory.insertData(self.speech_reco_event, [])
                self.onInput_onStop()
                sys.exit(0)
            # If the user said a Repeat keyword
            elif any(repeat_kw in sentence.lower() for repeat_kw in self.repeat_keywords):
                # If a previous sentence to repeat exists
                if self.previous_sentence:
                    self.repeat = True
                    if language == "it":
                        repeat_msg = "Certamente. Ho detto: "
                    else:
                        repeat_msg = "Sure! I said: "
                    self.animated_speech.say(self.voice_speed + repeat_msg + str(self.previous_sentence),
                                             self.configuration)
                else:
                    if language == "it":
                        repeat_msg = "Mi dispiace, non ho niente da ripetere."
                    else:
                        repeat_msg = "I'm sorry, I have nothing to repeat."
                    self.animated_speech.say(self.voice_speed + repeat_msg, self.configuration)

            elif any(stop_reco_kw in sentence.lower() for stop_reco_kw in self.stop_recording_keywords):
                self.stop_recording = True
                self.animated_speech.say(self.voice_speed + "Ok, non ti ascolterò più. Ricomincerò ad ascoltarti solo quando dirai ascoltami.", self.configuration)
                user_input = ""
                while True:
                    # Restart asr service
                    self.asr_service.pause(False)
                    self.asr_service.subscribe("Test_ASR")
                    time.sleep(5)
                    try:
                        answer = self.memory.getData("WordRecognized")[0]
                    except IndexError as e:
                        print(e)
                        answer = ""
                    self.asr_service.pause(True)
                    self.asr_service.unsubscribe("Test_ASR")
                    self.logger.info(answer)

                    # Exit
                    if answer == "ascoltami":
                        self.animated_speech.say(self.voice_speed + "Ok, ti sto ascoltando.", self.configuration)
                        break
                    else:
                        self.memory.insertData("WordRecognized", [])

            # If the user did not ask to exit or to repeat something, send the sentence to the server
            if not self.repeat and not self.stop_recording:
                # Compose the payload of the message to be sent to the server
                data = {"client_sentence": sentence, "dialogue_state": dialogue_state}
                encoded_data = json.dumps(data).encode('utf-8')
                compressed_data = zlib.compress(encoded_data)
                hub_response = requests.put(request_uri, data=compressed_data, verify=False)
                # If the Hub cannot contact the dialogue service, the response will be empty
                if hub_response:
                    # Overwrite the array containing the states of the profiles with those contained in the Hub response
                    dialogue_state = hub_response.json()['dialogue_state']
                    # Store the updated dictionary in the file
                    with open(self.dialogue_state_file_path, 'w') as f:
                        json.dump(dialogue_state, f)
                else:
                    self.logger.info("No response received from the Hub!")
                    self.onInput_onStop()
                    exit(0)

                plan_sentence = hub_response.json()['plan_sentence']
                plan = hub_response.json()['plan']
                dialogue_sentence = hub_response.json()['dialogue_sentence']

                # If there is an intent reply, it means that something has been matched by the Plan manager service
                if plan_sentence:
                    self.logger.info(str(plan_sentence))
                    # Say the plan sentence
                    self.animated_speech.say(self.voice_speed + str(plan_sentence), self.configuration)

                if plan:
                    self.logger.info(str(plan))
                    plan_items = plan.split("#")[1:]
                    self.logger.info(plan_items)
                    # For each action in the plan, check which action is it and execute it
                    # (if the corresponding behavior is installed)
                    for item in plan_items:
                        item = item.encode('utf-8')
                        self.plans.perform_action(item)

                    # Once the execution of the plan is finished, set the dialogue mode image on the tablet
                    if self.tablet:
                        self.tablet_service.showImage("http://" + self.tablet_service.robotIp() +
                                                      "/apps/" + app_name + "/img/DialogueMode.png")

                # Say the dialogue sentence
                self.logger.info(str(dialogue_sentence))
                dialogue_sentence = dialogue_sentence.replace("ə", "")
                self.animated_speech.say(self.voice_speed + str(dialogue_sentence), self.configuration)
                self.previous_sentence = dialogue_sentence

    def onInput_onStop(self):
        if self.tablet:
            self.tablet_service.hideImage()
        # self.al.setState("interactive")
        # If present, delete the transformation - if the robot moves outside CAIR it is no more valid
        try:
            self.memory.removeData("CAIR/transformation_matrix")
            self.memory.removeData("CAIR/theta")
        except:
            self.logger.info("No transformation to delete in memory.")
            pass
        sys.exit(0)]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /></Box><Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="2" /><Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="4" /></Diagram></BehaviorKeyframe></BehaviorLayer></Timeline></Box></ChoregrapheProject>