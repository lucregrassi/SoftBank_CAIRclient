<?xml version="1.0" encoding="UTF-8" ?><ChoregrapheProject xmlns="http://www.aldebaran-robotics.com/schema/choregraphe/project.xsd" xar_version="3"><Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0"><bitmap>media/images/box/root.png</bitmap><script language="4"><content><![CDATA[]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /><Timeline enable="0"><BehaviorLayer name="behavior_layer1"><BehaviorKeyframe name="keyframe1" index="1"><Diagram><Box name="Go To" id="1" localization="8" tooltip="This box contains a Python script that allows the robot to go to the specified location. The destination place should already be present in the map, and the robot should know where it is with respect to the environment before it can go somewhere." x="239" y="81"><bitmap>media/images/box/box-python-script.png</bitmap><script language="4"><content><![CDATA[import sys
import qi
import numpy as np
import motion
import argparse
from naoqi import ALProxy
import os


class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.memory = ALProxy("ALMemory")
        self.memory.subscribeToEvent("TouchChanged", self.getName(), "onTouched")

        self.motionProxy = ALProxy("ALMotion")
        self.motionProxy.setExternalCollisionProtectionEnabled("All", False)

        self.motionProxy.wakeUp()
        # For NAO robot
        self.motionProxy.setMotionConfig([["ENABLE_FOOT_CONTACT_PROTECTION", True]])

        self.al = ALProxy("ALAutonomousLife")

        self.animated_speech = ALProxy("ALAnimatedSpeech")
        self.configuration = {"bodyLanguageMode": "contextual"}
        try:
            self.voice_speed = "\\RSPD=" + str(self.memory.getData("CAIR/voice_speed")) + "\\"
        except:
            self.voice_speed = "\\RSPD=80\\"
        try:
            self.language = self.memory.getData("CAIR/language")
        except:
            self.language = "en"
        self.gain = 0.2
        self.isRunning = True

    def setAutonomousAbilities(self, blinking, background, awareness, listening, speaking):
        self.al.setAutonomousAbilityEnabled("AutonomousBlinking", blinking)
        self.al.setAutonomousAbilityEnabled("BackgroundMovement", background)
        self.al.setAutonomousAbilityEnabled("BasicAwareness", awareness)
        self.al.setAutonomousAbilityEnabled("ListeningMovement", listening)
        self.al.setAutonomousAbilityEnabled("SpeakingMovement", speaking)

    # Called everytime a robot sensor is touched: stops the movement and sets isRunning to False
    def onTouched(self, strVarName, value):
        self.logger.info("touched")
        self.motionProxy.stopMove()
        self.isRunning = False

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    # This function reads the map.txt file and returns a dictionary with the places as keys and the coordinates as values.
    def get_places_from_map(self):
        # The file map.txt will surely exist because it comes empty with the application
        with open("/data/home/nao/.local/share/PackageManager/apps/movement/map.txt", 'r') as f:
            lines = f.readlines()

        places = {}
        for line in lines:
            if line != '\n':
                place = line.split('_')[0]
                self.logger.info(str(place))
                X = float(line.split('_')[1])
                Y = float(line.split('_')[2])
                Theta = float(line.split('_')[3])
                places[place] = (X, Y, Theta)
        return places


    def onInput_onStart(self):

        where = str(self.memory.getData("CAIR/go_to"))
        self.logger.info(where)
        where = where.strip()

        places = self.get_places_from_map()

        if where in places.keys():
            Px_w = places[where][0]
            Py_w = places[where][1]
            Pz_w = 1.0
            Ptheta_w = places[where][2]
            destination = [Px_w, Py_w, Pz_w, Ptheta_w]
            print "Destination:", destination

            # Try to move to that place only if the it is known!
            odometry = self.motionProxy.getRobotPosition(True)
            Px_r = odometry[0]
            Py_r = odometry[1]
            Ptheta_r = odometry[2]
            P_r = [Px_r, Py_r, 1.0]

            try:
                transformation_matrix = self.memory.getData("CAIR/transformation_matrix")
                theta = self.memory.getData("CAIR/theta")
                Pr_w = np.dot(transformation_matrix, np.array([P_r]).T)
                Pr_w = [round(Pr_w[0], 2), round(Pr_w[1], 2), 1.0, round(Ptheta_r + theta, 2)]
                self.logger.info("Position of the robot wrt the world:" + str(Pr_w))

                relative_destination = [dest - robot_pos for dest, robot_pos in zip(destination, Pr_w)]
                self.logger.info("Relative destination:" + str(relative_destination))
                # Difference between destination and current position (just X, Y and Z - no theta)
                theta_rotation = Pr_w[3]

                rotation_matrix = np.array([[np.cos(theta_rotation), np.sin(theta_rotation)],
                                            [-np.sin(theta_rotation), np.cos(theta_rotation)]])

                x_y_relative_dest = np.array([relative_destination[0], relative_destination[1]])
                relative_movement = np.dot(rotation_matrix, x_y_relative_dest.T)
                self.logger.info("Relative movement: " + str(relative_movement) + str(theta_rotation))
                if self.language == "it":
                    to_say = "Sto andando in " + where + ". Tocca uno dei miei sensori se vuoi che mi fermi."

                else:
                    to_say = "I'm going to the " + where + ". Touch one of my sensors if you want me to stop."
                self.animated_speech.say(self.voice_speed + to_say, self.configuration)

                ######### CHANGE WITH VELOCITIES ###########
                self.motionProxy.moveTo(round(relative_movement[0], 2), round(relative_movement[1], 2), relative_destination[3])

                while self.isRunning and self.motionProxy.moveIsActive():
                    pass

                self.memory.insertData("CAIR/go_to_outcome", True)
                odometry = self.motionProxy.getRobotPosition(True)
                Px_r = odometry[0]
                Py_r = odometry[1]
                Ptheta_r = odometry[2]
                P_r = [Px_r, Py_r, 1.0]
                Pr_w = np.dot(transformation_matrix, np.array([P_r]).T)
                Pr_w = [round(Pr_w[0], 2), round(Pr_w[1], 2), 1.0, round(Ptheta_r + theta, 2)]
                self.logger.info("Position of the robot wrt the world:" + str(Pr_w))
                self.memory.removeData("CAIR/go_to")
                self.onInput_onStop()

            except:
                if self.language == "it":
                    to_say = "Ho bisogno di sapere dove sono rispetto all'ambiente prima che io possa andare da qualche parte."
                else:
                    to_say = "I need to know where I am with respect to the environment before I can go somewhere."
                self.animated_speech.say(self.voice_speed + to_say, self.configuration)
                self.memory.insertData("CAIR/go_to_outcome", False)
                self.memory.removeData("CAIR/go_to")
                self.onInput_onStop()

        else:
            if self.language == "it":
                to_say = "Mi dispiace non so dove sia " + where + "."
            else:
                to_say = "I'm sorry I don't know where the " + where + " is."
            self.animated_speech.say(self.voice_speed + to_say, self.configuration)
            self.memory.insertData("CAIR/go_to_outcome", False)
            self.memory.removeData("CAIR/go_to")
            self.onInput_onStop()


    def onInput_onStop(self):
        self.motionProxy.setExternalCollisionProtectionEnabled("All", True)
        self.onUnload() #it is recommended to reuse the clean-up as the box is stopped
        self.onStopped() #activate the output of the box]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /></Box><Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="2" /><Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="4" /></Diagram></BehaviorKeyframe></BehaviorLayer></Timeline></Box></ChoregrapheProject>