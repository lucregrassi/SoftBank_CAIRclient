<?xml version="1.0" encoding="UTF-8" ?><ChoregrapheProject xmlns="http://www.aldebaran-robotics.com/schema/choregraphe/project.xsd" xar_version="3"><Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0"><bitmap>media/images/box/root.png</bitmap><script language="4"><content><![CDATA[]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /><Timeline enable="0"><BehaviorLayer name="behavior_layer1"><BehaviorKeyframe name="keyframe1" index="1"><Diagram><Box name="Play Song" id="1" localization="8" tooltip="This box contains a basic Python script to play music. It  retrieves eventual missing parameters and asks the user if he/she wants to watch also the video of the requested song." x="239" y="67"><bitmap>media/images/box/box-python-script.png</bitmap><script language="4"><content><![CDATA[import sys
import qi
import urllib2
import re
import time
from naoqi import ALProxy


class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.motionProxy = ALProxy("ALMotion")
        self.memory = ALProxy("ALMemory")
        self.al = ALProxy("ALAutonomousLife")
        self.sASR = ALProxy("ASR2")
        self.animated_speech = ALProxy("ALAnimatedSpeech")
        try:
            self.voice_speed = "\\RSPD=" + str(self.memory.getData("CAIR/voice_speed")) + "\\"
        except:
            self.voice_speed = "\\RSPD=80\\"
        try:
            self.language = self.memory.getData("CAIR/language")
        except:
            self.language = "en"
        self.configuration = {"bodyLanguageMode": "contextual"}
        self.speech_reco_event = "Audio/RecognizedWords"

        # Things needed to understand if the user wants to watch the video
        self.asr_service = ALProxy("ALSpeechRecognition")
        # asr needs to be paused before changing the language and setting the vocabulary
        self.asr_service.pause(True)
        # change the language to overcome vocabulary problem
        self.asr_service.setLanguage("Italian")
        self.asr_service.setLanguage("English")
        vocabulary = ["yes", "sÃ¬", "si", "no"]
        self.asr_service.pause(True)
        self.asr_service.setVocabulary(vocabulary, False)
        self.asr_service.setAudioExpression(False)

        self.behavior_manager = ALProxy("ALBehaviorManager")

    def setAutonomousAbilities(self, blinking, background, awareness, listening, speaking):
        self.al.setAutonomousAbilityEnabled("AutonomousBlinking", blinking)
        self.al.setAutonomousAbilityEnabled("BackgroundMovement", background)
        self.al.setAutonomousAbilityEnabled("BasicAwareness", awareness)
        self.al.setAutonomousAbilityEnabled("ListeningMovement", listening)
        self.al.setAutonomousAbilityEnabled("SpeakingMovement", speaking)

    def onLoad(self):
        pass

    def onUnload(self):
        pass

    def onInput_onStart(self):
        # Check if the parameter is in memory
        try:
            text = self.memory.getData("CAIR/song_title")
            self.logger.info(str(text))
            if text == "None" or "music" in text or text == "a song":
                raise Exception("No data")
        # If there is no parameter, ask for it
        except:
            if self.language == "it":
                ask_title = "Per favore, dimmi il titolo della canzone che vuoi ascoltare."
                reco_language = "Italian"
            else:
                ask_title =  "Please, tell me the title of the song you want to listen to."
                reco_language = "English"
            self.animated_speech.say(self.voice_speed + ask_title, self.configuration)

            # Start speech recognition
            self.sASR.startReco(reco_language, False, True)
            self.setAutonomousAbilities(True, True, True, True, True)

            start_time_silence = time.time() + 1800

            sentence = ""
            reco_speech = self.memory.getData(self.speech_reco_event)
            self.logger.info(str(reco_speech))
            stop = False

            while True:
                time.sleep(0.1)
                while not reco_speech:
                    time.sleep(0.1)
                    if sentence and time.time() - start_time_silence > 0.1:
                        self.sASR.stopReco()
                        self.setAutonomousAbilities(False, True, True, True, True)
                        stop = True
                        break
                    reco_speech = self.memory.getData(self.speech_reco_event)
                    print reco_speech
                sys.stdout.flush()
                if stop:
                    break
                if sentence == "":
                    sep = ""
                else:
                    sep = " "

                if reco_speech:
                    sentence = sentence + sep + reco_speech[0][0]
                start_time_silence = time.time()
                self.memory.insertData(self.speech_reco_event, [])
                reco_speech = self.memory.getData(self.speech_reco_event)

                exit_keywords = ["stop", "exit", "quit"]
                if sentence.lower() in exit_keywords:
                    self.onInput_onStop()
                    sys.exit(0)

            sentence = sentence.replace(" ", "_")
            print sentence
            self.logger.info(str(sentence))
            self.memory.insertData(self.speech_reco_event, [])
            self.memory.insertData("CAIR/song_title", str(sentence))

        # You can also ask the user if they also want to see the video or just listen to the song

        # Call the play-video behavior
        self.behavior_manager.runBehavior("musicplayer/play-video")
        while self.behavior_manager.isBehaviorRunning("musicplayer/play-video"):
            pass

        self.memory.removeData("CAIR/song_title")
        self.onInput_onStop()

    def onInput_onStop(self):
        self.onUnload() #it is recommended to reuse the clean-up as the box is stopped
        self.onStopped() #activate the output of the box]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /></Box><Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="2" /><Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="4" /></Diagram></BehaviorKeyframe></BehaviorLayer></Timeline></Box></ChoregrapheProject>