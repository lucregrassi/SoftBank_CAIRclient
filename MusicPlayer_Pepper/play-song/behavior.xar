<?xml version="1.0" encoding="UTF-8" ?><ChoregrapheProject xmlns="http://www.aldebaran-robotics.com/schema/choregraphe/project.xsd" xar_version="3"><Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0"><bitmap>media/images/box/root.png</bitmap><script language="4"><content><![CDATA[]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /><Timeline enable="0"><BehaviorLayer name="behavior_layer1"><BehaviorKeyframe name="keyframe1" index="1"><Diagram><Box name="Play Song" id="1" localization="8" tooltip="This box contains a basic Python script to play music. It  retrieves eventual missing parameters and asks the user if he/she wants to watch also the video of the requested song." x="239" y="67"><bitmap>media/images/box/box-python-script.png</bitmap><script language="4"><content><![CDATA[import sys
import qi
import urllib2
import re
import time
from naoqi import ALProxy


class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.motionProxy = ALProxy("ALMotion")
        self.memory = ALProxy("ALMemory")
        self.al = ALProxy("ALAutonomousLife")
        self.animated_speech = ALProxy("ALAnimatedSpeech")
        try:
            self.voice_speed = "\\RSPD=" + str(self.memory.getData("CAIR/voice_speed")) + "\\"
        except:
            self.voice_speed = "\\RSPD=80\\"
        try:
            self.language = self.memory.getData("CAIR/language")
        except:
            self.language = "en"
        self.configuration = {"bodyLanguageMode": "contextual"}

        # Things needed to understand if the user wants to watch the video
        self.asr_service = ALProxy("ALSpeechRecognition")
        # asr needs to be paused before changing the language and setting the vocabulary
        self.asr_service.pause(True)
        # change the language to overcome vocabulary problem
        self.asr_service.setLanguage("Italian")
        self.asr_service.setLanguage("English")
        vocabulary = ["yes", "sÃ¬", "si", "no"]
        self.asr_service.pause(True)
        self.asr_service.setVocabulary(vocabulary, False)
        self.asr_service.setAudioExpression(False)

        self.behavior_manager = ALProxy("ALBehaviorManager")

    def setAutonomousAbilities(self, blinking, background, awareness, listening, speaking):
        self.al.setAutonomousAbilityEnabled("AutonomousBlinking", blinking)
        self.al.setAutonomousAbilityEnabled("BackgroundMovement", background)
        self.al.setAutonomousAbilityEnabled("BasicAwareness", awareness)
        self.al.setAutonomousAbilityEnabled("ListeningMovement", listening)
        self.al.setAutonomousAbilityEnabled("SpeakingMovement", speaking)

    def onLoad(self):
        pass

    def onUnload(self):
        pass

    def onInput_onStart(self):
        # Check if the parameter is in memory
        text = self.memory.getData("CAIR/song_title")
        self.logger.info(str(text))

        if self.language == "it":
            ask_video = "Vuoi che ti mostri anche il video?"
        else:
            ask_video = "Do you want me to show you also the video?"
        # Once the parameter is obtained, ask the user if he/she wants to watch also the video
        self.animated_speech.say(self.voice_speed + ask_video, self.configuration)

        # Restart asr service
        self.asr_service.pause(False)
        self.asr_service.subscribe("Test_ASR")
        time.sleep(4)
        answer = self.memory.getData("WordRecognized")[0]
        self.asr_service.unsubscribe("Test_ASR")
        self.logger.info(answer)

        # Call the play-video behavior
        if answer == "yes":
            self.behavior_manager.runBehavior("musicplayer/play-video")
            while self.behavior_manager.isBehaviorRunning("musicplayer/play-video"):
                pass

        # Call the play-song behavior
        else:
            self.behavior_manager.runBehavior("musicplayer/play-music")
            while self.behavior_manager.isBehaviorRunning("musicplayer/play-music"):
                pass

        self.memory.removeData("CAIR/song_title")
        self.onInput_onStop()


    def onInput_onStop(self):
        self.onUnload() #it is recommended to reuse the clean-up as the box is stopped
        self.onStopped() #activate the output of the box]]></content></script><Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" /><Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" /><Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" /><Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" /></Box><Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="2" /><Link inputowner="0" indexofinput="4" outputowner="1" indexofoutput="4" /></Diagram></BehaviorKeyframe></BehaviorLayer></Timeline></Box></ChoregrapheProject>